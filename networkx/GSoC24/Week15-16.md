---
title: "Blog8: GSoC (nx-parallel)"
author: Aditi Juneja
date: 2024-09-06 19:48:00 +0530
---

# Blog8: GSoC (nx-parallel)

## Week 15-16 (10th August to 26th August, 2024)

### GSoC - Coding Period (Phase 2)

## TL;DR

In Weeks 15-16 of GSoC (Phase 2), built nx-parallel's configuration system to support both joblib and NetworkX (PR#75). Discussions are ongoing on whether to synchronize these configurations (Issue#76). Some algorithms showing less than 1 speedups, leading to further investigation (Issues #77, #79). Re-engaged the author of PR#7, sparking insightful discussions on the future direction of nx-parallel. Additionally, I would love to work on the proposal of the C++ backend for NetworkX(Discussions #7612). Lastly, presented a talk with Erik at EuroSciPy on networkx dispatching and nx-parallel.

## 1. Adding algorithms to nx-parallel

During this phase, I implemented several parallel algorithms. Initially, I added `colliders` and `v_structures` in [PR#74](https://github.com/networkx/nx-parallel/pull/74), and earlier, while working as an Independent Contractor, I added `global_reaching_centrality` and `local_reaching_centrality` in [PR#44](https://github.com/networkx/nx-parallel/pull/44). I also experimented with parallel implementations for `average_clustering`, `approximate_average_clustering`, and `transitive_closure_dag`. Unfortunately, they yielded speedups close to 1, with some even showing fractional speedups, meaning the parallel versions were slower than the non-parallel implementations. There is also `number_of_isolates` in nx-parallel which has the same behaviour. As a result, I paused work on these algorithms while we explore ways to address these issues. For further discussions on handling such algorithms, I opened two related issues:

- Addressing Slower Parallel Implementations in nx-parallel Compared to NetworkX: [Issue#79](https://github.com/networkx/nx-parallel/issues/79)
- Incorporating `should_run` in nx-parallel: [Issue#77](https://github.com/networkx/nx-parallel/issues/77) - for adding `should_run` we can probably take some inspiration from cugraphs.

## 2. Pre-commit hook for updating `get_info`

In [PR#55](https://github.com/networkx/nx-parallel/pull/55) (Adding a pre-commit hook to update get_info), there wasn't much debate during this phrase and it got merged.

## 3. Configurations in nx-parallel

I closed the old [PR#68](https://github.com/networkx/nx-parallel/pull/68) (WIP: Adding config to nx-parallel) for adding configuration support and opened a new one: ENH: Adding and documenting configs in nx-parallel - [PR#75](https://github.com/networkx/nx-parallel/pull/75). Now, nx-parallel supports two configuration systems: joblib and NetworkX. I updated the package documentation accordingly, with most of the details in `Config.md`. Additionally, development discussions are thoroughly documented in the PR comments.

While working on this, I also introduced another PR based on Dan's review to exclude utility functions from `get_info`- [PR#78](https://github.com/networkx/nx-parallel/pull/78).

I also raised an issue discussing synchronization of the NetworkX and joblib configuration systems, though I’m uncertain if this would complicate things further and whether we should do it or not - [Issue#76](https://github.com/networkx/nx-parallel/issues/76).

## 4. Future work

All throughout these blog you will find many loose threads and issues sprinkled around but for some of the major ones I have created issues in the nx-parallel repository, and also I have documented the important future work items in [my gsoc final report](https://docs.google.com/document/d/1t7mZNv2f_8BjUGpfSOyNhtpCgUHTboP5VpRbrPII-nU/edit?usp=sharing) in the "Future Work" section. And some of the points from my initial gsoc proposal that were in the "Experimental" section are yet to be refined as problems and explored and worked on.

I also reviewed and closed the long-standing [PR#7](https://github.com/networkx/nx-parallel/pull/7), which brought up an important consideration—whether we want a global map-reduce structure in nx-parallel. This led to the PR's author becoming active again and now we are continuing having discussions on how we want to shape nx-parallel. And it has been really fun interacting with them and getting their views has been insightful :) And I think we can evolve nx-parallel into something actually really nice.

I plan to review the open PRs on nx-parallel now that GSoC and EuroSciPy are over:

- [PR#72](https://github.com/networkx/nx-parallel/pull/72) : feat ✨ : Add closeness centrality and floyd warshall feature
- [PR#80](https://github.com/networkx/nx-parallel/pull/80) : Chore/style cleanup utility functions

I’m also planning to conduct sprints at PyCon India and potentially give a lightning talk, depending on whether my proposals are accepted.

## 5. Other Activities in the Community

- Delivered the EuroSciPy talk on networkx dispatching and nx-parallel backend with Erik :) [[Slides](https://github.com/Schefflera-Arboricola/euroscipy2024)]
- At EuroSciPy, I was also helping with the session on [Dispatching, Backend Selection, and Compatibility APIs](https://pretalx.com/euroscipy-2024/talk/8MXPRW/)
- **Reviewed** [PR#7568](https://github.com/networkx/networkx/pull/7568) - Log "can/should run" and caching in dispatch machinery
- **Reviewed** [PR#7599](https://github.com/networkx/networkx/pull/7599) - DOC: Rm redundant module from autosummary.
- **Resolved** [Issue#7598](https://github.com/networkx/networkx/issues/7598) - Networkx use np.alltrue which is deprecated and is removed in numpy 2.0+
- **Commented** [Discussions#7612](https://github.com/networkx/networkx/discussions/7612) - A C++ backend for networkX - Proposal to Compile Performance-Critical Functions for Improved Efficiency : I really look forward to working on this.

FIN :)

PS: Thank you for this opportunity to contribute to NetworkX during GSoC! It has truly been a privilege and I look forward to contributing more to the community :)
